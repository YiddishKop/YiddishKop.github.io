<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2018-08-12 日 21:55 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>scikit-笔记03:训练集与测试集</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="yiddi" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
 <link rel='stylesheet' href='css/site.css' type='text/css'/>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2018 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
</head>
<body>
<div id="org-div-home-and-up">
 <a accesskey="h" href="index.html"> UP </a>
 |
 <a accesskey="H" href="/index.html"> HOME </a>
</div><div id="content">
<h1 class="title">scikit-笔记03:训练集与测试集</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org2803d03">1. Training and Testing Data</a>
<ul>
<li>
<ul>
<li><a href="#orgffb7415">1.0.1. load datasets, create estimator by <code>load_iris()</code> and <code>KNeighborsClassifier()</code></a></li>
<li><a href="#orgaed32e0">1.0.2. split datasets <code>train_test_split()</code></a></li>
<li><a href="#org04d0c87">1.0.3. stratify split vs. non-stratify split</a></li>
<li><a href="#orga4f6c50">1.0.4. non-stratify</a></li>
<li><a href="#org8f9a385">1.0.5. stratify</a></li>
<li><a href="#org22dcbb3">1.0.6. get model by <code>estimator.fit</code> and predict by <code>estimator.predict</code></a></li>
<li><a href="#orgcc8a6ee">1.0.7. plotting correctly labeled data, and incorrectly labeled data</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgb69277e">2. Exercise</a></li>
<li><a href="#orge45aebf">3. Misc tools</a>
<ul>
<li><a href="#org19074ac">3.1. Scikit-learn</a>
<ul>
<li><a href="#orgd5a0d76">3.1.1. train_test_split(X,y,test_size=0.5, train_size=0.5, stratify=y)</a></li>
<li><a href="#org465bbc3">3.1.2. ML models by now</a></li>
</ul>
</li>
<li><a href="#orgb61c0e5">3.2. Numpy</a>
<ul>
<li><a href="#orgb6019da">3.2.1. np.where(condition, x, y)</a></li>
<li><a href="#orgd469133">3.2.2. eg0. produce the index, given <code>condition</code></a></li>
<li><a href="#org5498418">3.2.3. eg1. choose elements, given <code>condition, x, y</code></a></li>
<li><a href="#org440ba3d">3.2.4. eg2. fill with default value, given <code>condition, x, y</code></a></li>
<li><a href="#orgbb1ec7c">3.2.5. eg3. return nonzero, given only <code>condition</code></a></li>
<li><a href="#org17e8bed">3.2.6. eg4. using as filtering, given only <code>condition</code></a></li>
<li><a href="#orgcd4c88b">3.2.7. np.nonzero(ndarray)</a></li>
<li><a href="#org5724bd0">3.2.8. ndarray + nonzero/where =&gt; x[np.nonzero(x)]</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div class="org-src-container">
<pre class="src src-ipython">%matplotlib inline
<span class="org-keyword">import</span> matplotlib.pyplot <span class="org-keyword">as</span> plt
<span class="org-keyword">import</span> numpy <span class="org-keyword">as</span> np

</pre>
</div>

<div id="org2803d03" class="outline-2">
<h2 id="org2803d03"><span class="section-number-2">1</span> Training and Testing Data</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="orgffb7415" class="outline-4">
<h4 id="orgffb7415"><span class="section-number-4">1.0.1</span> load datasets, create estimator by <code>load_iris()</code> and <code>KNeighborsClassifier()</code></h4>
<div class="outline-text-4" id="text-1-0-1">
<p>
To evaluate how well our supervised models generalize, we can split our data
into a training and a test set:
</p>


<div class="figure">
<p><img src="figures/train_test_split_matrix.png" alt="train_test_split_matrix.png" />
</p>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">from</span> sklearn.datasets <span class="org-keyword">import</span> load_iris
<span class="org-keyword">from</span> sklearn.neighbors <span class="org-keyword">import</span> KNeighborsClassifier

<span class="org-variable-name">iris</span> = load_iris()
<span class="org-variable-name">X</span>, <span class="org-variable-name">y</span> = iris.data, iris.target

<span class="org-variable-name">classifier</span> = KNeighborsClassifier()
</pre>
</div>

<p>
Thinking about how machine learning is normally performed, the idea of a
train/test split makes sense.
</p>

<p>
Under the assumption that all samples are independent of each other (<b>in
contrast time series data</b>), we want to <b>randomly shuffle the dataset</b> before we
split the dataset as illustrated above.
</p>

<div class="org-src-container">
<pre class="src src-ipython">y
</pre>
</div>

<pre class="example">
array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
</pre>
</div>
</div>

<div id="orgaed32e0" class="outline-4">
<h4 id="orgaed32e0"><span class="section-number-4">1.0.2</span> split datasets <code>train_test_split()</code></h4>
<div class="outline-text-4" id="text-1-0-2">
<p>
Now we need to split the data into training and testing. Luckily, this is a
common pattern in machine learning and scikit-learn has a pre-built function to
split data into training and testing sets for you. Here, we use 50% of the data
as training, and 50% testing. 80% and 20% is another common split, but there are
no hard and fast rules. The most important thing is to fairly evaluate your
system on data it has not seen during training!
</p>
</div>
</div>

<div id="org04d0c87" class="outline-4">
<h4 id="org04d0c87"><span class="section-number-4">1.0.3</span> stratify split vs. non-stratify split</h4>
<div class="outline-text-4" id="text-1-0-3">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">train_test_split(<code>stratify=y</code>)</th>
<th scope="col" class="org-left">train_test_split(<code>stratify=None</code>)</th>
</tr>

<tr>
<th scope="col" class="org-left">'y' means split by the related proportion of 'y' label</th>
<th scope="col" class="org-left">&#xa0;</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">All: [ 33.33333333  33.33333333  33.33333333]</td>
<td class="org-left">All: [ 33.33333333  33.33333333  33.33333333]</td>
</tr>

<tr>
<td class="org-left">Training: [ 33.33333333  33.33333333  33.33333333]</td>
<td class="org-left">Training: [ 30.66666667  40.     29.33333333]</td>
</tr>

<tr>
<td class="org-left">Test: [ 33.33333333  33.33333333  33.33333333]</td>
<td class="org-left">Test: [ 36.          26.66666667  37.33333333]</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
</tr>
</tbody>
<tbody>
<tr>
<td class="org-left">better for small dataset</td>
<td class="org-left">better for large dataset</td>
</tr>
</tbody>
</table>
</div>
</div>

<div id="orga4f6c50" class="outline-4">
<h4 id="orga4f6c50"><span class="section-number-4">1.0.4</span> non-stratify</h4>
<div class="outline-text-4" id="text-1-0-4">
<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">from</span> sklearn.model_selection <span class="org-keyword">import</span> train_test_split

<span class="org-variable-name">train_X</span>, <span class="org-variable-name">test_X</span>, <span class="org-variable-name">train_y</span>, <span class="org-variable-name">test_y</span> = train_test_split(X, y,
                                                    train_size=<span class="org-highlight-numbers-number">0</span>.<span class="org-highlight-numbers-number">5</span>,
                                                    test_size=<span class="org-highlight-numbers-number">0</span>.<span class="org-highlight-numbers-number">5</span>,
                                                    random_state=<span class="org-highlight-numbers-number">123</span>)
<span class="org-keyword">print</span>(<span class="org-string">"Labels for training and testing data"</span>)
<span class="org-keyword">print</span>(train_y)
<span class="org-keyword">print</span>(test_y)
<span class="org-keyword">print</span>(<span class="org-string">'All:'</span>, np.bincount(y) / <span class="org-builtin">float</span>(<span class="org-builtin">len</span>(y)) * <span class="org-highlight-numbers-number">100</span>.<span class="org-highlight-numbers-number">0</span>)
<span class="org-keyword">print</span>(<span class="org-string">'Training:'</span>, np.bincount(train_y) / <span class="org-builtin">float</span>(<span class="org-builtin">len</span>(train_y)) * <span class="org-highlight-numbers-number">100</span>.<span class="org-highlight-numbers-number">0</span>)
<span class="org-keyword">print</span>(<span class="org-string">'Test:'</span>, np.bincount(test_y) / <span class="org-builtin">float</span>(<span class="org-builtin">len</span>(test_y)) * <span class="org-highlight-numbers-number">100</span>.<span class="org-highlight-numbers-number">0</span>)
</pre>
</div>

<p>
All: [ 33.33333333  33.33333333  33.33333333]
Training: [ 30.66666667  40.          29.33333333]
Test: [ 36.          26.66666667  37.33333333]
</p>
</div>
</div>

<div id="org8f9a385" class="outline-4">
<h4 id="org8f9a385"><span class="section-number-4">1.0.5</span> stratify</h4>
<div class="outline-text-4" id="text-1-0-5">
<p>
Especially for relatively small datasets, it's better to stratify the split.
</p>

<blockquote>
<p>
Stratification means that we maintain the original class proportion of the
dataset in the test and training sets.
</p>
</blockquote>

<p>
For example, after we randomly split the dataset as shown in the previous code
example, we have the following class proportions in percent:
</p>

<p>
So, in order to stratify the split, we can pass the label array as an additional
option to the train_test_split function:
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">train_X</span>, <span class="org-variable-name">test_X</span>, <span class="org-variable-name">train_y</span>, <span class="org-variable-name">test_y</span> = train_test_split(X, y,
                                                    train_size=<span class="org-highlight-numbers-number">0</span>.<span class="org-highlight-numbers-number">5</span>,
                                                    test_size=<span class="org-highlight-numbers-number">0</span>.<span class="org-highlight-numbers-number">5</span>,
                                                    random_state=<span class="org-highlight-numbers-number">123</span>,
                                                    stratify=y)

<span class="org-keyword">print</span>(<span class="org-string">'All:'</span>, np.bincount(y) / <span class="org-builtin">float</span>(<span class="org-builtin">len</span>(y)) * <span class="org-highlight-numbers-number">100</span>.<span class="org-highlight-numbers-number">0</span>)
<span class="org-keyword">print</span>(<span class="org-string">'Training:'</span>, np.bincount(train_y) / <span class="org-builtin">float</span>(<span class="org-builtin">len</span>(train_y)) * <span class="org-highlight-numbers-number">100</span>.<span class="org-highlight-numbers-number">0</span>)
<span class="org-keyword">print</span>(<span class="org-string">'Test:'</span>, np.bincount(test_y) / <span class="org-builtin">float</span>(<span class="org-builtin">len</span>(test_y)) * <span class="org-highlight-numbers-number">100</span>.<span class="org-highlight-numbers-number">0</span>)
</pre>
</div>

<p>
All: [ 33.33333333  33.33333333  33.33333333]
Training: [ 33.33333333  33.33333333  33.33333333]
Test: [ 33.33333333  33.33333333  33.33333333]
</p>
</div>
</div>

<div id="org22dcbb3" class="outline-4">
<h4 id="org22dcbb3"><span class="section-number-4">1.0.6</span> get model by <code>estimator.fit</code> and predict by <code>estimator.predict</code></h4>
<div class="outline-text-4" id="text-1-0-6">
<p>
By evaluating our classifier performance on data that has been seen during
training, we could get false confidence in the predictive power of our model. In
the worst case, it may simply memorize the training samples but completely fails
classifying new, similar samples &#x2013; we really don't want to put such a system
into production!
</p>

<p>
Instead of using the same dataset for training and testing (this is called
"resubstitution evaluation"), it is much much better to use a train/test split
in order to estimate how well your trained model is doing on new data.
</p>

<div class="org-src-container">
<pre class="src src-ipython">classifier.fit(train_X, train_y)
<span class="org-variable-name">pred_y</span> = classifier.predict(test_X)

<span class="org-keyword">print</span>(<span class="org-string">"Fraction Correct [Accuracy]:"</span>)
<span class="org-keyword">print</span>(np.<span class="org-builtin">sum</span>(pred_y == test_y) / <span class="org-builtin">float</span>(<span class="org-builtin">len</span>(test_y)))

</pre>
</div>
</div>
</div>

<div id="orgcc8a6ee" class="outline-4">
<h4 id="orgcc8a6ee"><span class="section-number-4">1.0.7</span> plotting correctly labeled data, and incorrectly labeled data</h4>
<div class="outline-text-4" id="text-1-0-7">
<p>
We can also visualize the correct and failed predictions
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">print</span>(<span class="org-string">'Samples correctly classified:'</span>)
<span class="org-variable-name">correct_idx</span> = np.where(pred_y == test_y)[<span class="org-highlight-numbers-number">0</span>] <span class="org-comment-delimiter">#</span><span class="org-comment">&lt;- return the correctly predicted row indices</span>
<span class="org-keyword">print</span>(correct_idx)

<span class="org-keyword">print</span>(<span class="org-string">'\nSamples incorrectly classified:'</span>)
<span class="org-variable-name">incorrect_idx</span> = np.where(pred_y != test_y)[<span class="org-highlight-numbers-number">0</span>] <span class="org-comment-delimiter">#</span><span class="org-comment">&lt;- return the incorrectly predicted row indices</span>
<span class="org-keyword">print</span>(incorrect_idx)

<span class="org-comment-delimiter"># </span><span class="org-comment">Plot two dimensions</span>
<span class="org-variable-name">colors</span> = [<span class="org-string">"darkblue"</span>, <span class="org-string">"darkgreen"</span>, <span class="org-string">"gray"</span>]

<span class="org-comment-delimiter"># </span><span class="org-comment">plot correctly labeled data with different color</span>
<span class="org-keyword">for</span> n, color <span class="org-keyword">in</span> <span class="org-builtin">enumerate</span>(colors):
    <span class="org-variable-name">idx</span> = np.where(test_y == n)[<span class="org-highlight-numbers-number">0</span>] <span class="org-comment-delimiter"># </span><span class="org-comment">get the indices of rows with certain label</span>
    plt.scatter(test_X[idx, <span class="org-highlight-numbers-number">1</span>], test_X[idx, <span class="org-highlight-numbers-number">2</span>], color=color, label=<span class="org-string">"Class %s"</span> % <span class="org-builtin">str</span>(n))

<span class="org-comment-delimiter"># </span><span class="org-comment">plot incorrectly labeled data with dark red</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">- for incorrect_idx rows get the data of label '1'</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">- for incorrect_idx rows get the data of label '2'</span>
plt.scatter(test_X[incorrect_idx, <span class="org-highlight-numbers-number">1</span>], test_X[incorrect_idx, <span class="org-highlight-numbers-number">2</span>], color=<span class="org-string">"darkred"</span>)

plt.xlabel(<span class="org-string">'sepal width [cm]'</span>)
plt.ylabel(<span class="org-string">'petal length [cm]'</span>)
plt.legend(loc=<span class="org-highlight-numbers-number">3</span>)
plt.title(<span class="org-string">"Iris Classification results"</span>)
plt.show()
</pre>
</div>


<div class="figure">
<p><img src="./obipy-resources/250412xI.png" alt="250412xI.png" />
</p>
</div>

<p>
We can see that the errors occur in the area where green (class 1) and gray
(class 2) overlap. This gives us insight about what features to add - any
feature which helps separate class 1 and class 2 should improve classifier
performance.
</p>
</div>
</div>
</div>

<div id="orgb69277e" class="outline-2">
<h2 id="orgb69277e"><span class="section-number-2">2</span> Exercise&#xa0;&#xa0;&#xa0;<span class="tag"><span class="EXERCISE">EXERCISE</span></span></h2>
<div class="outline-text-2" id="text-2">
<p>
EXERCISE: Print the true labels of 3 wrong predictions and modify the
scatterplot code, which we used above, to visualize and distinguish these three
samples with different markers in the 2D scatterplot. Can you explain why our
classifier made these wrong predictions?
</p>
</div>
</div>

<div id="orge45aebf" class="outline-2">
<h2 id="orge45aebf"><span class="section-number-2">3</span> Misc tools</h2>
<div class="outline-text-2" id="text-3">
</div>
<div id="org19074ac" class="outline-3">
<h3 id="org19074ac"><span class="section-number-3">3.1</span> Scikit-learn</h3>
<div class="outline-text-3" id="text-3-1">
</div>
<div id="orgd5a0d76" class="outline-4">
<h4 id="orgd5a0d76"><span class="section-number-4">3.1.1</span> train_test_split(X,y,test_size=0.5, train_size=0.5, stratify=y)</h4>
<div class="outline-text-4" id="text-3-1-1">
<p>
<a href="#orga4f6c50">non-stratify</a>
<a href="#org8f9a385">stratify</a>
</p>
</div>
</div>
<div id="org465bbc3" class="outline-4">
<h4 id="org465bbc3"><span class="section-number-4">3.1.2</span> ML models by now</h4>
<div class="outline-text-4" id="text-3-1-2">
<blockquote>
<ol class="org-ol">
<li>from sklearn.datasets import make_blobs</li>
<li>from sklearn.datasets import load_iris</li>
<li>from sklearn.model_selection import train_test_split</li>
<li>from sklearn.linear_model import LogisticRegression</li>
<li>from sklearn.neighbors import KNeighborsClassifier</li>
</ol>
</blockquote>
</div>
</div>
</div>
<div id="orgb61c0e5" class="outline-3">
<h3 id="orgb61c0e5"><span class="section-number-3">3.2</span> Numpy</h3>
<div class="outline-text-3" id="text-3-2">
</div>
<div id="orgb6019da" class="outline-4">
<h4 id="orgb6019da"><span class="section-number-4">3.2.1</span> np.where(condition, x, y)</h4>
<div class="outline-text-4" id="text-3-2-1">
<p>
Return elements, <b>either from x or y, depending on condition</b>.
</p>

<p>
<b>If only condition is given, return <code>condition.nonzero()</code>.</b>
</p>

<p>
这个函数返回的是一个 tuple of arrays, 指示的正好是符合 condition 的坐标.
</p>
</div>
</div>


<div id="orgd469133" class="outline-4">
<h4 id="orgd469133"><span class="section-number-4">3.2.2</span> eg0. produce the index, given <code>condition</code></h4>
<div class="outline-text-4" id="text-3-2-2">
<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">x</span> = np.arange(<span class="org-highlight-numbers-number">9</span>.).reshape(<span class="org-highlight-numbers-number">3</span>, <span class="org-highlight-numbers-number">3</span>)

<span class="org-comment-delimiter"># </span><span class="org-comment">array([[0., 1., 2.],</span>
<span class="org-comment-delimiter">#        </span><span class="org-comment">[3., 4., 5.],</span>
<span class="org-comment-delimiter">#        </span><span class="org-comment">[6., 7., 8.]])</span>

np.where(x)
<span class="org-comment-delimiter">#</span>
<span class="org-comment-delimiter">#        </span><span class="org-comment">dim-0 &#22352;&#26631;                       dim-1 &#22352;&#26631;</span>
<span class="org-comment-delimiter">#        </span><span class="org-comment">|                                |</span>
<span class="org-comment-delimiter">#        </span><span class="org-comment">v                                v</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">(array([0, 0, 1, 1, 1, 2, 2, 2]), array([1, 2, 0, 1, 2, 0, 1, 2]))</span>

np.where(x&gt;<span class="org-highlight-numbers-number">5</span>)
<span class="org-comment-delimiter"># </span><span class="org-comment">(array([2, 2, 2]), array([0, 1, 2]))</span>


x[np.where(x&gt;<span class="org-highlight-numbers-number">5</span>)]
<span class="org-comment-delimiter"># </span><span class="org-comment">array([6., 7., 8.])</span>

</pre>
</div>
</div>
</div>

<div id="org5498418" class="outline-4">
<h4 id="org5498418"><span class="section-number-4">3.2.3</span> eg1. choose elements, given <code>condition, x, y</code>&#xa0;&#xa0;&#xa0;<span class="tag"><span class="TECHCOMBO">TECHCOMBO</span></span></h4>
<div class="outline-text-4" id="text-3-2-3">
<p>
where( how_to_choose, x, y )
</p>
<div class="org-src-container">
<pre class="src src-ipython">np.where([[<span class="org-constant">True</span>, <span class="org-constant">False</span>], [<span class="org-constant">True</span>, <span class="org-constant">True</span>]],
         [[<span class="org-highlight-numbers-number">1</span>, <span class="org-highlight-numbers-number">2</span>], [<span class="org-highlight-numbers-number">3</span>, <span class="org-highlight-numbers-number">4</span>]],
         [[<span class="org-highlight-numbers-number">9</span>, <span class="org-highlight-numbers-number">8</span>], [<span class="org-highlight-numbers-number">7</span>, <span class="org-highlight-numbers-number">6</span>]])

<span class="org-comment-delimiter"># </span><span class="org-comment">return:</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">array([[1, 8],</span>
<span class="org-comment-delimiter">#        </span><span class="org-comment">[3, 4]])</span>

</pre>
</div>

<pre class="example">
array([[1, 8],
[3, 4]])
</pre>

<blockquote>
<p>
.
. True means, value of this location is selected from related location of 1st ndarray
. False means, value of this location is selected from related location of 2nd ndarray
.
. which array to choose for the same location
. [[True, False], [True, True]]                    1st: [[1, 2], [3, 4]]
.    ^      ^       ^      ^                              ✓       ✓  ✓
.    |      |       |      |
.   1st    2nd     1st    1st                      2nd: [[9, 8], [7, 6]]
.                                                            ✓
.
.             ===&gt;          [[1, 8],[3, 4]]
.
</p>
</blockquote>
</div>
</div>

<div id="org440ba3d" class="outline-4">
<h4 id="org440ba3d"><span class="section-number-4">3.2.4</span> eg2. fill with default value, given <code>condition, x, y</code>&#xa0;&#xa0;&#xa0;<span class="tag"><span class="TECHCOMBO">TECHCOMBO</span></span></h4>
<div class="outline-text-4" id="text-3-2-4">
<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">x</span> = np.arange(<span class="org-highlight-numbers-number">9</span>.).reshape(<span class="org-highlight-numbers-number">3</span>, <span class="org-highlight-numbers-number">3</span>)
<span class="org-comment-delimiter"># </span><span class="org-comment">[[ 0.  1.  2.]</span>
<span class="org-comment-delimiter">#  </span><span class="org-comment">[ 3.  4.  5.]</span>
<span class="org-comment-delimiter">#  </span><span class="org-comment">[ 6.  7.  8.]]</span>

np.where(x &lt; <span class="org-highlight-numbers-number">5</span>, x, -<span class="org-highlight-numbers-number">1</span>)               <span class="org-comment-delimiter"># </span><span class="org-comment">Note: broadcasting.</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">array([[ 0.,  1.,  2.],</span>
<span class="org-comment-delimiter">#        </span><span class="org-comment">[ 3.,  4., -1.],</span>
<span class="org-comment-delimiter">#        </span><span class="org-comment">[-1., -1., -1.]])</span>
</pre>
</div>

<pre class="example">
array([[ 0.,  1.,  2.],
[ 3.,  4., -1.],
[-1., -1., -1.]])
</pre>
</div>
</div>

<div id="orgbb1ec7c" class="outline-4">
<h4 id="orgbb1ec7c"><span class="section-number-4">3.2.5</span> eg3. return nonzero, given only <code>condition</code>&#xa0;&#xa0;&#xa0;<span class="tag"><span class="TECHCOMBO">TECHCOMBO</span></span></h4>
<div class="outline-text-4" id="text-3-2-5">
<div class="org-src-container">
<pre class="src src-ipython"><span class="org-comment-delimiter"># </span><span class="org-comment">&lt;- only given condition, so this will return np.nonzero(arr)</span>
<span class="org-variable-name">arr</span> = np.array([[<span class="org-highlight-numbers-number">0</span>, <span class="org-highlight-numbers-number">1</span>],[<span class="org-highlight-numbers-number">1</span>, <span class="org-highlight-numbers-number">0</span>]])
<span class="org-variable-name">nonz</span> = np.where(arr)
</pre>
</div>

<p>
0 - 54918791-5f6d-4269-bdeb-d8b05651576f
</p>
</div>
</div>
<div id="org17e8bed" class="outline-4">
<h4 id="org17e8bed"><span class="section-number-4">3.2.6</span> eg4. using as filtering, given only <code>condition</code>&#xa0;&#xa0;&#xa0;<span class="tag"><span class="TECHCOMBO">TECHCOMBO</span></span></h4>
<div class="outline-text-4" id="text-3-2-6">
<div class="org-src-container">
<pre class="src src-ipython">np.where( x &gt; <span class="org-highlight-numbers-number">5</span> )
<span class="org-comment-delimiter"># </span><span class="org-comment">(array([2, 2, 2]), array([0, 1, 2]))</span>

x[np.where( x &gt; <span class="org-highlight-numbers-number">5</span> )]               <span class="org-comment-delimiter"># </span><span class="org-comment">Note: result is 1D.</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">array([ 6.,  7.,  8.])</span>

</pre>
</div>
</div>
</div>

<div id="orgcd4c88b" class="outline-4">
<h4 id="orgcd4c88b"><span class="section-number-4">3.2.7</span> np.nonzero(ndarray)</h4>
<div class="outline-text-4" id="text-3-2-7">
<p>
Return the <b>indices</b> in the manner of tuple of array of the elements that
are non-zero.
</p>

<p>
Returns a tuple of arrays, one for each dimension of a, containing the
indices of the non-zero elements in that dimension.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">x</span> = np.array([[<span class="org-highlight-numbers-number">1</span>,<span class="org-highlight-numbers-number">0</span>,<span class="org-highlight-numbers-number">0</span>], [<span class="org-highlight-numbers-number">0</span>,<span class="org-highlight-numbers-number">2</span>,<span class="org-highlight-numbers-number">0</span>], [<span class="org-highlight-numbers-number">1</span>,<span class="org-highlight-numbers-number">1</span>,<span class="org-highlight-numbers-number">0</span>]])
np.nonzero(x)
</pre>
</div>

<pre class="example">
(array([0, 1, 2, 2]), array([0, 1, 0, 1]))

</pre>

<blockquote>
<p>
.
. |       | 0 col | 1 col | 2 col |
. |-------<del>-------</del>--&#x2013;&#x2014;+--&#x2013;&#x2014;|
. | 0 row |     1 |     0 |     0 |
. | 1 row |     0 |     2 |     0 |
. | 2 row |     1 |     1 |     0 |
.
. indices of non zero:
.           (0, 0)
.           (1, 1)
.           (2, 0)
.           (2, 1)
.            ^  ^
.            |  +&#x2014; [0, 1, 0, 1]
.  [0, 1, 2, 2]
.
</p>
</blockquote>
</div>
</div>

<div id="org5724bd0" class="outline-4">
<h4 id="org5724bd0"><span class="section-number-4">3.2.8</span> ndarray + nonzero/where =&gt; x[np.nonzero(x)]&#xa0;&#xa0;&#xa0;<span class="tag"><span class="TECHCOMBO">TECHCOMBO</span></span></h4>
<div class="outline-text-4" id="text-3-2-8">
<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">x</span> = np.array([[<span class="org-highlight-numbers-number">1</span>,<span class="org-highlight-numbers-number">0</span>,<span class="org-highlight-numbers-number">0</span>], [<span class="org-highlight-numbers-number">0</span>,<span class="org-highlight-numbers-number">2</span>,<span class="org-highlight-numbers-number">0</span>], [<span class="org-highlight-numbers-number">1</span>,<span class="org-highlight-numbers-number">1</span>,<span class="org-highlight-numbers-number">0</span>]])
x[np.nonzero(x)]               <span class="org-comment-delimiter"># </span><span class="org-comment">Note: result is 1D.</span>
</pre>
</div>

<pre class="example">
array([1, 2, 1, 1])

</pre>

<blockquote>
<p>
.
.   nonzero &#x2014;&gt; dimension_num-tuple of ndarray
.
. x:
. |       | 0 col | 1 col | 2 col |
. |-------<del>-------</del>--&#x2013;&#x2014;+--&#x2013;&#x2014;|
. | 0 row | ✓ 1   | 0     |     0 |
. | 1 row | 0     | ✓ 2   |     0 |
. | 2 row | ✓ 1   | ✓ 1   |     0 |
.
. indices of non zero:
.           (0, 0)
.           (1, 1)
.           (2, 0)
.           (2, 1)
.            ^  ^
.            |  |
. [0, 1, 2, 2]  [0, 1, 0, 1]
. --------------------------&#x2013;&#x2014;
. ([0,1,2,2], [0,1,0,1])
.
.
.  x[np.nonzero(x)] = [1,2,1,1]
.
</p>
</blockquote>
</div>
</div>
</div>
</div>
</div>
</body>
</html>
